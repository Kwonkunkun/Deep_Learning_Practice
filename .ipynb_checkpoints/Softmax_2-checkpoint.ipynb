{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27692b645bdf48b49d6ab718de3b5cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ea7f8a44b54168a1cc8b6f3c7bbff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc036fab86a1499e936fa349f83df9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d01257b1b4429c8057ed78140d35a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Model\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "    \n",
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.303375\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.302634\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.302986\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.301151\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.308034\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.297120\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.300100\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.294068\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.302761\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.282799\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.295218\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.303951\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.291854\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.291473\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.294438\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.296864\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.294345\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.299342\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.298651\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.285032\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.304850\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.300003\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.288359\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.306773\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.289335\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.298825\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.283232\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.293559\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.299198\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.289486\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.294900\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.282513\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.285772\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.284378\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.286626\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.294991\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.288739\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.285114\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.286041\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.290960\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.282555\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.278846\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.268221\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.276802\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.277986\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.271324\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.267634\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.261408\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.263772\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.260278\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.257590\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.246728\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.272771\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.267756\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.260179\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.239052\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.240157\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.234236\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.243685\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.241663\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.246976\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.204032\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.207619\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.218540\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.222017\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.177656\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.176918\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.186767\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.148249\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.134218\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.120245\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.086495\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.109310\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.049066\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.081290\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.007441\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 1.974323\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.009682\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 1.893372\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 1.811919\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 1.871662\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 1.833288\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 1.687155\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 1.711822\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.734033\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 1.632755\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.568699\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.521800\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.418094\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.460428\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.324742\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.388642\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.325632\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.294741\n",
      "Training time: 0m 23s\n",
      "===========================\n",
      "Test set: Average loss: 0.0198, Accuracy: 6278/10000 (63%)\n",
      "Testing time: 0m 26s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.167930\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.163369\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.442740\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.288318\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.019181\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.026046\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.168043\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.916645\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.032691\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.055372\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.896621\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.798551\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.870629\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.775313\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.925601\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.720973\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.071656\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.721832\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.825404\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.641751\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.716549\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.548546\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.752212\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.765869\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.770968\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.544486\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.516357\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.698247\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.786200\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.627084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.648722\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.504622\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.776027\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.658883\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.508162\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.604266\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 1.060242\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.487538\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.456170\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.507860\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.686430\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.633952\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.482553\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.518350\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.865968\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.690129\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.605860\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.769485\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.541279\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.592330\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.661771\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.387958\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.363523\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.500904\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.481206\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.427356\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.393437\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.720075\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.485994\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.434853\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.573429\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.521240\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.267012\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.524932\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.400028\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.672256\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.447489\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.663073\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.424052\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.448588\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.316055\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.665871\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.869125\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.324781\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.646943\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.408719\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.384352\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.500298\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.358037\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.389923\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.559303\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.625536\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.355852\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.571143\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.499039\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.539838\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.362600\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.330556\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.279549\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.334696\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.443232\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.343065\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.600128\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.375808\n",
      "Training time: 0m 24s\n",
      "===========================\n",
      "Test set: Average loss: 0.0064, Accuracy: 8813/10000 (88%)\n",
      "Testing time: 0m 26s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.296885\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.635747\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.506444\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.402582\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.382593\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.251515\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.388428\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.360386\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.307524\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.504899\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.356073\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.399629\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.291789\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.520975\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.439044\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.578550\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.474973\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.601237\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.251889\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.425155\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.479690\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.351206\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.418109\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.269584\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.328218\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.481038\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.334456\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.213165\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.320910\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.254003\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.532055\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.405421\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.401785\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.363718\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.287606\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.347915\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.380208\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.179255\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.386638\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.470708\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.557186\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.416978\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.286811\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.244923\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.288103\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.557196\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.372519\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.346929\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.472296\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.310028\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.281051\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.281026\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.379662\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.302878\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.540364\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.195977\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.225773\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.223537\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.363686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.282542\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.185389\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.134600\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.483727\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.318117\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.508472\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.338322\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.190423\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.377273\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.277737\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.477435\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.214157\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.356639\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.203023\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.340136\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.245708\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.329379\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.468904\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.195603\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.139705\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.332700\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.218757\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.380373\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.460260\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.266475\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.197381\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.332799\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.295832\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.391777\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.427790\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.344636\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.206297\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.489736\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.246062\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.164982\n",
      "Training time: 0m 24s\n",
      "===========================\n",
      "Test set: Average loss: 0.0046, Accuracy: 9176/10000 (92%)\n",
      "Testing time: 0m 26s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.142904\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.215264\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.333839\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.176048\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.303663\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.434714\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.584548\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.469768\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.242413\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.191578\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.216838\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.284010\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.196177\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.209274\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.161894\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.134259\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.331063\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.214656\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.236659\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.205529\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.348730\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.363578\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.241943\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.377899\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.249979\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.279458\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.111128\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.117160\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.178944\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.277985\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.285612\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.119670\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.206982\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.174656\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.121598\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.166865\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.343585\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.154879\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.225755\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.312437\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.274480\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.140018\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.205119\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.143827\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.311724\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.209439\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.253841\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.243680\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.292998\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.238386\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.220349\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.192780\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.186904\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.225954\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.165010\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.331052\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.231969\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.302377\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.208500\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.121274\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.327872\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.159003\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.463866\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.268383\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.337873\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.325678\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.136066\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.188323\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.195283\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.319031\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.130605\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.208100\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.143319\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.219807\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.072871\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.394313\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.207153\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.217503\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.105289\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.121057\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.343314\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.164205\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.196807\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.244706\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.217761\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.430358\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.196716\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.284170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.332547\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.320293\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.096956\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.219572\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.151542\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.261630\n",
      "Training time: 0m 23s\n",
      "===========================\n",
      "Test set: Average loss: 0.0032, Accuracy: 9399/10000 (94%)\n",
      "Testing time: 0m 25s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.188081\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.258452\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.226918\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.130995\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.156908\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.343060\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.107900\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.196755\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.302088\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.394030\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.156778\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.231891\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.205877\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.225867\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.240523\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.243801\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.242483\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.243871\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.148529\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.159200\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.178467\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.152959\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.172175\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.286321\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.189060\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.195725\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.161851\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.241948\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.217754\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.175305\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.117238\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.198477\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.197736\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.148005\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.117058\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.335489\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.194593\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.144192\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.235179\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.119472\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.053224\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.111091\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.134165\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.289706\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.168503\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.211517\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.132320\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.236852\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.395037\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.169376\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.172899\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.284635\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.094508\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.105955\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.137074\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.066968\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.139361\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.255044\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.117789\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.205597\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.069992\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.189173\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.084120\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.112409\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.177165\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.204003\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.085005\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.169338\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.120542\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.122334\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.240620\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.124483\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.208393\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.092046\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.210881\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.238155\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.153968\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.177586\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.059140\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.098140\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.206213\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.156677\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.134611\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.250443\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.153408\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.102788\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.161118\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.093035\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.108234\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.072540\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.189236\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.062697\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.125947\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.070297\n",
      "Training time: 0m 25s\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9519/10000 (95%)\n",
      "Testing time: 0m 28s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.114252\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.067540\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.097853\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.221452\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.088998\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.098144\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.066155\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.280741\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.025022\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.188971\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.093815\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.111106\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.076163\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.236951\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.166478\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.103427\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.143208\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.105412\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.199066\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.159545\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.141601\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.151524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.088058\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.185688\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.115089\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.085974\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.043274\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.124908\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.152048\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.119284\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.086492\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.246603\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.208459\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.124215\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.076318\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.214779\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.296443\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.088919\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.208434\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.082067\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.099568\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.154551\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.055436\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.293033\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.080037\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.054378\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.089021\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.132202\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.161346\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.228671\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.192744\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.067156\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.176307\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.152430\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.122711\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.081462\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.171420\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.046081\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.102799\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.094557\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.197556\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.307638\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.133984\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.127909\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.062281\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.103470\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.149902\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.126348\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.233212\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.096135\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.105848\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.022655\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.075821\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.065182\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.254215\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.212978\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.202651\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.050900\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.088425\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.107217\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.147382\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.159652\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.208664\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.117020\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.083151\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.102232\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.183951\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.082234\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.084298\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.069892\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.227448\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.175772\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.143577\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.063902\n",
      "Training time: 0m 26s\n",
      "===========================\n",
      "Test set: Average loss: 0.0021, Accuracy: 9613/10000 (96%)\n",
      "Testing time: 0m 28s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.250549\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.124271\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.275967\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.099319\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.094306\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.250104\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.068551\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.098372\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.167739\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.131157\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.062608\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.147912\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.058424\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.151153\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.076171\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.265724\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.040954\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.095242\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.028124\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.125229\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.180276\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.276685\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.083917\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.101945\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.222539\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.062420\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.141929\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.210774\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.027950\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.085059\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.029077\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.273988\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.280567\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.067344\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.263670\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.112754\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.130182\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.057515\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.046708\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.046613\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.142664\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.300214\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.043432\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.154338\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.033062\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.074282\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.205074\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.124620\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.078375\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.099173\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.128514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.179423\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.131098\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.161247\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.142362\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.206376\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.102845\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.049077\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.077822\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.039110\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.049104\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.105418\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.166388\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.121514\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.242263\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.196759\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.093395\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.148445\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.166116\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.129418\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.029541\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.063689\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.074676\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.200371\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.160201\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.075358\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.101282\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.048822\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.127301\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.196235\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.091369\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.089693\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.021278\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.125762\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.060095\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.207684\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.125428\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.190779\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.212658\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.179195\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.084162\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.166592\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.146911\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.096810\n",
      "Training time: 0m 25s\n",
      "===========================\n",
      "Test set: Average loss: 0.0020, Accuracy: 9640/10000 (96%)\n",
      "Testing time: 0m 28s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.061908\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.046687\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.105314\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.032101\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.126799\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.253011\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.102488\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.116510\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.018999\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.061009\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.121431\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.105352\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.057859\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.191821\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.125020\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.116638\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.124579\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.061884\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.058046\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.065470\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.059443\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.051108\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.066233\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.088353\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.146574\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.050356\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.111570\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.369858\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.052694\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.088415\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.103093\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.108142\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.056902\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.235846\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.162172\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.073060\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.132714\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.034420\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.237022\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.120460\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.052838\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.121453\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.055641\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.054604\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.174992\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.089275\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.030459\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.158932\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.119417\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.179594\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.093152\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.182257\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.034532\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.050056\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.085290\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.084771\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.104095\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.097552\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.064343\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.074529\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.244930\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.119639\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.173071\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.133090\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.060008\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.039634\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.009914\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.094291\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.093172\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.031496\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.128248\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.070686\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.222344\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.106672\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.357896\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.123214\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.137820\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.249937\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.030423\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.142020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.176188\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.133035\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.052458\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.164504\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.048771\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.030969\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.019385\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.014255\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.124800\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.201453\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.102174\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.060909\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.059847\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.023556\n",
      "Training time: 0m 26s\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9644/10000 (96%)\n",
      "Testing time: 0m 29s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.056452\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.194361\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.170562\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.032022\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.103822\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.083165\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.086850\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.054486\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.079204\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.105197\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.111601\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.056509\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.058936\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.016122\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.062820\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.070802\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.057136\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.062108\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.074407\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.153586\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.028951\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.108507\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.053706\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.101778\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.056042\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.208020\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.032647\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.059058\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.097069\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.245031\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.063406\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.150020\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.176761\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.080023\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.045037\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.121542\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.055035\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.037896\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.083870\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.058932\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.084536\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.031132\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.119850\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.077668\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.094817\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.062623\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.057365\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.058966\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.078671\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.203610\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.085897\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.035550\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.065457\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.056830\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.080282\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.018094\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.087177\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.138057\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.041556\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.025376\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.045293\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.076232\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.167639\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.071240\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.156942\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.076312\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.017987\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.062632\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.161799\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.141973\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.088835\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.047498\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.256909\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.039011\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.049090\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.029412\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.104756\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.018779\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.008386\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.039120\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.049862\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.092877\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.148413\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.087857\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.161453\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.050306\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.091493\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.087081\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.025139\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.049071\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.233220\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.273483\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.258763\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.116284\n",
      "Training time: 0m 29s\n",
      "===========================\n",
      "Test set: Average loss: 0.0016, Accuracy: 9695/10000 (97%)\n",
      "Testing time: 0m 31s\n",
      "Total Time: 4m 6s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
